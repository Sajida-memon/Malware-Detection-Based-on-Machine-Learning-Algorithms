Synthetic Data Generation:

The generate_synthetic_data function creates a dataset with 200 samples. Each sample is represented by a binary sequence of length 20, and the labels are randomly assigned to one of the three classes: phishing, trojan horse, or denial of service.
Preprocessing:

The data is standardized using StandardScaler to ensure that the features have a mean of 0 and a standard deviation of 1. This is important for many machine learning algorithms.
Train-Test Split:

The dataset is split into training (70%) and testing (30%) sets using train_test_split.
Machine Learning Models:

Three different machine learning models are defined:
Logistic Regression
Random Forest
Support Vector Machine (SVM)
Each model is trained on the training data and then used to predict the test data. The accuracy, classification report, and confusion matrix are printed for each model.
Confusion Matrix Visualization:

The confusion matrix is plotted for each model using seaborn to visualize the performance of the model in distinguishing between the different types of malware.
Running the Code:
When you run this code, you will get the accuracy, classification report, and confusion matrix for each of the three models. The confusion matrix will give you a visual representation of how well the model is performing in distinguishing between the different classes.

This basic example can be extended and refined with more sophisticated feature extraction methods, larger datasets, and hyperparameter tuning for better performance in real-world scenarios.

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Generate a synthetic dataset
def generate_synthetic_data(num_samples=200, sequence_length=20):
    np.random.seed(42)
    # Random binary sequences for malware features
    X = np.random.randint(0, 2, (num_samples, sequence_length))
    # Labels: 0 = phishing, 1 = trojan horse, 2 = denial of service
    y = np.random.choice([0, 1, 2], num_samples)
    return X, y

# Load data
X, y = generate_synthetic_data()

# Preprocess data
scaler = StandardScaler()
X = scaler.fit_transform(X)  # Standardize features

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Define machine learning models
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "Support Vector Machine": SVC()
}

# Train and evaluate models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{name} Accuracy: {accuracy:.2f}")
    print(f"{name} Classification Report:")
    print(classification_report(y_test, y_pred))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()
